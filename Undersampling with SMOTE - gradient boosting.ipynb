{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2672cd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    420\n",
      "1    420\n",
      "Name: sentiment, dtype: int64\n",
      "학습 데이터셋 정확도: 0.927\n",
      "테스트 데이터셋 정확도: 0.752\n",
      "[0.16635357 0.         0.10536875 0.05989751 0.12651041 0.08691218\n",
      " 0.11121928 0.01138682 0.0120705  0.0169421  0.         0.\n",
      " 0.00969631 0.01347145 0.         0.         0.01919561 0.03530927\n",
      " 0.01799226 0.01961136 0.01419106 0.00826882]\n",
      "['Game_Runtime' 'Phase' 'Hunger_PLAYER' 'Health_PLAYER' 'Sanity_PLAYER'\n",
      " 'Player_Xloc' 'Player_Zloc' 'Curr_Inv_Cnt_PLAYER' 'Distance' 'log_P'\n",
      " 'rock_P' 'grass_P']\n",
      "AUC: 0.8434058717746661\n",
      "Accuracy: 0.769\n",
      "Precision: 0.480\n",
      "Recall: 0.821\n",
      "F1-score: 0.606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x2880 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#KOR1sec - feature selection(2) - under sampling(1/3) + SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "import warnings; warnings.filterwarnings(action='ignore') # 경고 메시지 무시\n",
    "import matplotlib.pyplot as plt # 데이터 시각화 라이브러리\n",
    "import pickle # 객체 입출력을 위한 라이브러리\n",
    "from sklearn.model_selection import train_test_split # 훈련 데이터, 테스트 데이터 분리\n",
    "from sklearn.preprocessing import StandardScaler # 정규화\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC # 랜덤포레스트 분류 알고리즘\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC # 의사결정나무 분류 알고리즘\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC # 그래디언트 부스팅 분류 알고리즘\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, plot_confusion_matrix\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from numpy import array \n",
    "########################\n",
    "\n",
    "UnderSampling = 1       # 1 : undersampling(size->1/3), 2 : undersampling(size->minority),   0 : not undersampling    \n",
    "OverSampling = 1        # 1 : oversampling(SMOTE),                                           0 : not oversampling\n",
    "selection = 2           # 1 : feature selection - RFEVC, 2 : feature selection - mutual information, 0 : not feature selection\n",
    "feat_start=1\n",
    "########################\n",
    "data = pd.read_csv('/Users/jun/Data/sentiment analysis - KOR/5초전데이터/sentiment+gamedata/KOR-1sec(fin).csv')\n",
    "scaler = StandardScaler()\n",
    "y = data['sentiment']\n",
    "X = data.drop(labels=['sentiment','file','time'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,random_state=7)\n",
    "# 설명변수 데이터 스케일링\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "feature_name = X.columns\n",
    "if UnderSampling == 1:\n",
    "    undersample = RandomUnderSampler(sampling_strategy=0.837) \n",
    "    X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "elif UnderSampling == 2:\n",
    "    undersample = RandomUnderSampler(sampling_strategy='majority') \n",
    "    X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "    \n",
    "if OverSampling == 1:\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    \n",
    "print(y_train.value_counts())\n",
    "\n",
    "def modeling_uncustomized (algorithm, X_train, y_train, X_test, y_test):\n",
    "    # 하이퍼파라미터 조정 없이 모델 학습\n",
    "    uncustomized = algorithm(random_state=1234)\n",
    "    uncustomized.fit(X_train, y_train)\n",
    "    # Train Data 설명력\n",
    "    train_score_before = uncustomized.score(X_train, y_train).round(3)\n",
    "    print(f\"학습 데이터셋 정확도: {train_score_before}\")\n",
    "    # Test Data 설명력\n",
    "    test_score_before = uncustomized.score(X_test, y_test).round(3)\n",
    "    print(f\"테스트 데이터셋 정확도: {test_score_before}\")\n",
    "    return train_score_before, test_score_before\n",
    "\n",
    "\n",
    "def optimi_visualization(algorithm_name, X_values, train_score, test_score, xlabel, filename):\n",
    "    # 하이퍼파라미터 조정에 따른 학습 데이터셋 기반 모델 성능 추이 시각화\n",
    "    plt.plot(X_values, train_score, linestyle = '-', label = 'train score')\n",
    "    # 하이퍼파라미터 조정에 따른 테스트 데이터셋 기반 모델 성능 추이 시각화\n",
    "    plt.plot(X_values, test_score, linestyle = '--', label = 'test score')\n",
    "    plt.ylabel('Accuracy(%)') # y축 라벨\n",
    "    plt.xlabel(xlabel) # x축 라벨\n",
    "    plt.legend() # 범례표시\n",
    "    \n",
    "def optimi_estimator(algorithm, algorithm_name, X_train, y_train, X_test, y_test, n_estimator_min, n_estimator_max):\n",
    "    train_score = []; test_score =[]\n",
    "    para_n_tree = [n_tree*5 for n_tree in range(n_estimator_min, n_estimator_max)]\n",
    "\n",
    "    for v_n_estimators in para_n_tree:\n",
    "        model = algorithm(n_estimators = v_n_estimators, random_state=1234)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 트리 개수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'n_estimators': para_n_tree, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 트리 개수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_n_tree, train_score, test_score, \"The number of estimator\", \"n_estimator\")\n",
    "    print(round(df_score_n, 4))\n",
    "\n",
    "\n",
    "def optimi_maxdepth (algorithm, algorithm_name, X_train, y_train, X_test, y_test, depth_min, depth_max, n_estimator):\n",
    "    train_score = []; test_score = []\n",
    "    para_depth = [depth for depth in range(depth_min, depth_max)]\n",
    "\n",
    "    for v_max_depth in para_depth:\n",
    "        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "        if algorithm == DTC:\n",
    "            model = algorithm(max_depth = v_max_depth,\n",
    "                              random_state=1234)\n",
    "        else:\n",
    "            model = algorithm(max_depth = v_max_depth,\n",
    "                              n_estimators = n_estimator,\n",
    "                              random_state=1234)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 최대 깊이에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'depth': para_depth, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 최대 깊이에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_depth, train_score, test_score, \"The number of depth\", \"n_depth\")\n",
    "    print(round(df_score_n, 4))\n",
    "    \n",
    "def optimi_minsplit (algorithm, algorithm_name, X_train, y_train, X_test, y_test, n_split_min, n_split_max, n_estimator, n_depth):\n",
    "    train_score = []; test_score = []\n",
    "    para_split = [n_split*2 for n_split in range(n_split_min, n_split_max)]\n",
    "    for v_min_samples_split in para_split:\n",
    "        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "        if algorithm == DTC:\n",
    "            model = algorithm(min_samples_split = v_min_samples_split,\n",
    "                              max_depth = n_depth,\n",
    "                              random_state = 1234)\n",
    "        else:\n",
    "            model = algorithm(min_samples_split = v_min_samples_split,\n",
    "                              n_estimators = n_estimator,\n",
    "                              max_depth = n_depth,\n",
    "                              random_state = 1234)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 분리 노드의 최소 자료 수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'min_samples_split': para_split, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 분리 노드의 최소 자료 수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_split, train_score, test_score, \"The minimum number of samples required to split an internal node\", \"min_samples_split\")\n",
    "    print(round(df_score_n, 4))\n",
    "    \n",
    "def optimi_minleaf(algorithm, algorithm_name, X_train, y_train, X_test, y_test, n_leaf_min, n_leaf_max, n_estimator, n_depth, n_split):\n",
    "    train_score = []; test_score = []\n",
    "    para_leaf = [n_leaf*2 for n_leaf in range(n_leaf_min, n_leaf_max)]\n",
    "\n",
    "    for v_min_samples_leaf in para_leaf:\n",
    "        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "        if algorithm == DTC:\n",
    "            model = algorithm(min_samples_leaf = v_min_samples_leaf,\n",
    "                                        max_depth = n_depth,\n",
    "                                        min_samples_split = n_split,\n",
    "                                        random_state=1234)\n",
    "        else:\n",
    "            model = algorithm(min_samples_leaf = v_min_samples_leaf,\n",
    "                                n_estimators = n_estimator,\n",
    "                                max_depth = n_depth,\n",
    "                                min_samples_split = n_split,\n",
    "                                random_state=1234)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 잎사귀 노드의 최소 자료 수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'min_samples_leaf': para_leaf, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 잎사귀 노드의 최소 자료 수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_leaf, train_score, test_score, \"The minimum number of samples required to be at a leaf node\", \"min_samples_leaf\")\n",
    "    print(round(df_score_n, 4))\n",
    "    \n",
    "def model_final(algorithm, algorithm_name, feature_name, X_train, y_train, X_test, y_test, n_estimator, n_depth, n_split, n_leaf, selection):\n",
    "    # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "    if algorithm == DTC:\n",
    "        model = algorithm(random_state=1234, \n",
    "                          min_samples_leaf = n_leaf,\n",
    "                          min_samples_split = n_split, \n",
    "                          max_depth = n_depth)\n",
    "    else:\n",
    "        model = algorithm(random_state = 1234, \n",
    "                          n_estimators = n_estimator, \n",
    "                          min_samples_leaf = n_leaf,\n",
    "                          min_samples_split = n_split, \n",
    "                          max_depth = n_depth)\n",
    "    \n",
    "    if selection == 1 :\n",
    "        selector = RFECV(model, min_features_to_select=5, step=1, cv = 5)\n",
    "        selector.fit(X_train, y_train)\n",
    "        selected_columns = X.columns[selector.support_]\n",
    "\n",
    "        print(selected_columns)\n",
    "        train_acc = selector.score(X_train, y_train)\n",
    "        test_acc = selector.score(X_test, y_test)\n",
    "        y_pred = selector.predict(X_test)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, selector.predict_proba(X_test)[:,1])\n",
    "        print('AUC: {}'.format(roc_auc))\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\") # 정확도\n",
    "        print(f\"Precision: {precision_score(y_test, y_pred):.3f}\") # 정밀도\n",
    "        print(f\"Recall: {recall_score(y_test, y_pred):.3f}\") # 재현율\n",
    "        print(f\"F1-score: {f1_score(y_test, y_pred):.3f}\") # F1 스코어\n",
    "\n",
    "        # 혼동행렬 시각화\n",
    "#         plt.figure(figsize =(40, 40))\n",
    "#         plot_confusion_matrix(model, X_test, y_test,include_values = True,display_labels = ['non-negative', 'negative'],cmap = 'Pastel1') # 컬러맵\n",
    "#         plt.show()\n",
    "\n",
    "        # 변수 중요도 산출\n",
    "        dt_importance = pd.DataFrame()\n",
    "        dt_importance['Feature'] = feature_name # 설명변수 이름\n",
    "        dt_importance['Rank'] = selector.ranking_ # 설명변수 중요도 산출\n",
    "\n",
    "        # 변수 중요도 내림차순 정렬\n",
    "        dt_importance.sort_values(\"Rank\", ascending = False, inplace = True)\n",
    "        print(dt_importance.round(3))\n",
    "        # 변수 중요도 오름차순 정렬\n",
    "        dt_importance.sort_values(\"Rank\", ascending = True, inplace = True)\n",
    "        # 변수 중요도 시각화\n",
    "        coordinates = range(len(dt_importance)) # 설명변수 개수만큼 bar 시각화\n",
    "        plt.barh(y = coordinates, width = dt_importance[\"Rank\"])\n",
    "        plt.yticks(coordinates, dt_importance[\"Feature\"]) # y축 눈금별 설명변수 이름 기입\n",
    "        plt.xlabel(\"Feature Rank\") # x축 이름\n",
    "        plt.ylabel(\"Features\") # y축 이름\n",
    "    elif selection == 2:\n",
    "        mi_score = mutual_info_classif(X,y)\n",
    "        print(mi_score)\n",
    "        selector = SelectKBest(mutual_info_classif, k=12)\n",
    "        selector.fit(X_train, y_train)\n",
    "        X_train = selector.transform(X_train)\n",
    "        X_test = selector.transform(X_test)\n",
    "        filter = selector.get_support()\n",
    "        features = array(feature_name)\n",
    "        print(features[filter])\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        score=selector.scores_\n",
    "        \n",
    "        train_acc = model.score(X_train, y_train)\n",
    "        test_acc = model.score(X_test, y_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "        print('AUC: {}'.format(roc_auc))\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\") # 정확도\n",
    "        print(f\"Precision: {precision_score(y_test, y_pred):.3f}\") # 정밀도\n",
    "        print(f\"Recall: {recall_score(y_test, y_pred):.3f}\") # 재현율\n",
    "        print(f\"F1-score: {f1_score(y_test, y_pred):.3f}\") # F1 스코어\n",
    "\n",
    "        # 혼동행렬 시각화\n",
    "        plt.figure(figsize =(40, 40))\n",
    "        plot_confusion_matrix(model, X_test, y_test,include_values = True,display_labels = ['non-negative', 'negative'],cmap = 'Pastel1') # 컬러맵\n",
    "        plt.show()\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "        # 최종 모델의 성능 평가\n",
    "        train_acc = model.score(X_train, y_train)\n",
    "        test_acc = model.score(X_test, y_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "        print('AUC: {}'.format(roc_auc))\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\") # 정확도\n",
    "        print(f\"Precision: {precision_score(y_test, y_pred):.3f}\") # 정밀도\n",
    "        print(f\"Recall: {recall_score(y_test, y_pred):.3f}\") # 재현율\n",
    "        print(f\"F1-score: {f1_score(y_test, y_pred):.3f}\") # F1 스코어\n",
    "\n",
    "        # 혼동행렬 시각화\n",
    "        plt.figure(figsize =(40, 40))\n",
    "        plot_confusion_matrix(model, X_test, y_test,include_values = True,display_labels = ['non-negative', 'negative'],cmap = 'Pastel1') # 컬러맵\n",
    "        plt.show()\n",
    "\n",
    "        # 변수 중요도 산출\n",
    "        dt_importance = pd.DataFrame()\n",
    "        dt_importance['Feature'] = feature_name # 설명변수 이름\n",
    "        dt_importance['Importance'] = model.feature_importances_ # 설명변수 중요도 산출\n",
    "\n",
    "        # 변수 중요도 내림차순 정렬\n",
    "        dt_importance.sort_values(\"Importance\", ascending = False, inplace = True)\n",
    "        print(dt_importance.round(3))\n",
    "        # 변수 중요도 오름차순 정렬\n",
    "        dt_importance.sort_values(\"Importance\", ascending = True, inplace = True)\n",
    "        # 변수 중요도 시각화\n",
    "        coordinates = range(len(dt_importance)) # 설명변수 개수만큼 bar 시각화\n",
    "        plt.barh(y = coordinates, width = dt_importance[\"Importance\"])\n",
    "        plt.yticks(coordinates, dt_importance[\"Feature\"]) # y축 눈금별 설명변수 이름 기입\n",
    "        plt.xlabel(\"Feature Importance\") # x축 이름\n",
    "        plt.ylabel(\"Features\") # y축 이름\n",
    "        \n",
    "    \n",
    "\n",
    "algorithm = GBC\n",
    "algorithm_name = 'gbc'\n",
    "train_acc_before, test_acc_before = modeling_uncustomized(algorithm, \n",
    "                                                          X_train,\n",
    "                                                          y_train,\n",
    "                                                          X_test,\n",
    "                                                          y_test)\n",
    "\n",
    "n_estimator = 100\n",
    "n_depth = 7\n",
    "n_split = 88\n",
    "n_leaf = 6\n",
    "\n",
    "model_final(algorithm, algorithm_name, feature_name,\n",
    "            X_train, y_train, X_test, y_test,\n",
    "            n_estimator, n_depth, n_split, n_leaf,selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af7297b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1491\n",
      "1    1491\n",
      "Name: sentiment, dtype: int64\n",
      "학습 데이터셋 정확도: 0.906\n",
      "테스트 데이터셋 정확도: 0.824\n",
      "[0.04033906 0.00072467 0.02037881 0.0147187  0.03529955 0.04248558\n",
      " 0.04562292 0.00177919 0.         0.00334118 0.002213   0.00697372\n",
      " 0.         0.00102239 0.00397896 0.00098542 0.02118933 0.\n",
      " 0.00017091 0.00420651 0.         0.01103305]\n",
      "['Game_Runtime' 'Phase' 'Health_PLAYER' 'Sanity_PLAYER' 'Player_Xloc'\n",
      " 'Player_Zloc' 'Curr_Inv_Cnt_PLAYER' 'Curr_Equip_Hands_PLAYER' 'log_P'\n",
      " 'grass_P' 'twig_P' 'flint_P']\n",
      "AUC: 0.8650964611196592\n",
      "Accuracy: 0.923\n",
      "Precision: 0.389\n",
      "Recall: 0.765\n",
      "F1-score: 0.516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x2880 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ENG 1sec - feature selection(2) - under sampling(1/3) + SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "import warnings; warnings.filterwarnings(action='ignore') # 경고 메시지 무시\n",
    "import matplotlib.pyplot as plt # 데이터 시각화 라이브러리\n",
    "import pickle # 객체 입출력을 위한 라이브러리\n",
    "from sklearn.model_selection import train_test_split # 훈련 데이터, 테스트 데이터 분리\n",
    "from sklearn.preprocessing import StandardScaler # 정규화\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC # 랜덤포레스트 분류 알고리즘\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC # 의사결정나무 분류 알고리즘\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC # 그래디언트 부스팅 분류 알고리즘\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, plot_confusion_matrix\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from numpy import array \n",
    "########################\n",
    "\n",
    "UnderSampling = 1       # 1 : undersampling(size->1/3), 2 : undersampling(size->minority),   0 : not undersampling    \n",
    "OverSampling = 1        # 1 : oversampling(SMOTE),                                           0 : not oversampling\n",
    "selection = 2           # 1 : feature selection - RFEVC, 2 : feature selection - mutual information, 0 : not feature selection\n",
    "feat_start=1\n",
    "########################\n",
    "data = pd.read_csv('/Users/jun/Data/sentiment analysis - ENG/5초전/사용할 파일/sentiment+gamedata/ENG-1sec(fin).csv')\n",
    "scaler = StandardScaler()\n",
    "y = data['sentiment']\n",
    "X = data.drop(labels=['sentiment','file','time'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,random_state=7)\n",
    "# 설명변수 데이터 스케일링\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "feature_name = X.columns\n",
    "if UnderSampling == 1:\n",
    "    undersample = RandomUnderSampler(sampling_strategy=0.1703) \n",
    "    X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "elif UnderSampling == 2:\n",
    "    undersample = RandomUnderSampler(sampling_strategy='majority') \n",
    "    X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "    \n",
    "if OverSampling == 1:\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    \n",
    "print(y_train.value_counts())\n",
    "\n",
    "def modeling_uncustomized (algorithm, X_train, y_train, X_test, y_test):\n",
    "    # 하이퍼파라미터 조정 없이 모델 학습\n",
    "    uncustomized = algorithm(random_state=1234)\n",
    "    uncustomized.fit(X_train, y_train)\n",
    "    # Train Data 설명력\n",
    "    train_score_before = uncustomized.score(X_train, y_train).round(3)\n",
    "    print(f\"학습 데이터셋 정확도: {train_score_before}\")\n",
    "    # Test Data 설명력\n",
    "    test_score_before = uncustomized.score(X_test, y_test).round(3)\n",
    "    print(f\"테스트 데이터셋 정확도: {test_score_before}\")\n",
    "    return train_score_before, test_score_before\n",
    "\n",
    "\n",
    "def optimi_visualization(algorithm_name, X_values, train_score, test_score, xlabel, filename):\n",
    "    # 하이퍼파라미터 조정에 따른 학습 데이터셋 기반 모델 성능 추이 시각화\n",
    "    plt.plot(X_values, train_score, linestyle = '-', label = 'train score')\n",
    "    # 하이퍼파라미터 조정에 따른 테스트 데이터셋 기반 모델 성능 추이 시각화\n",
    "    plt.plot(X_values, test_score, linestyle = '--', label = 'test score')\n",
    "    plt.ylabel('Accuracy(%)') # y축 라벨\n",
    "    plt.xlabel(xlabel) # x축 라벨\n",
    "    plt.legend() # 범례표시\n",
    "    \n",
    "def optimi_estimator(algorithm, algorithm_name, X_train, y_train, X_test, y_test, n_estimator_min, n_estimator_max):\n",
    "    train_score = []; test_score =[]\n",
    "    para_n_tree = [n_tree*5 for n_tree in range(n_estimator_min, n_estimator_max)]\n",
    "\n",
    "    for v_n_estimators in para_n_tree:\n",
    "        model = algorithm(n_estimators = v_n_estimators, random_state=1234)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 트리 개수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'n_estimators': para_n_tree, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 트리 개수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_n_tree, train_score, test_score, \"The number of estimator\", \"n_estimator\")\n",
    "    print(round(df_score_n, 4))\n",
    "\n",
    "\n",
    "def optimi_maxdepth (algorithm, algorithm_name, X_train, y_train, X_test, y_test, depth_min, depth_max, n_estimator):\n",
    "    train_score = []; test_score = []\n",
    "    para_depth = [depth for depth in range(depth_min, depth_max)]\n",
    "\n",
    "    for v_max_depth in para_depth:\n",
    "        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "        if algorithm == DTC:\n",
    "            model = algorithm(max_depth = v_max_depth,\n",
    "                              random_state=1234)\n",
    "        else:\n",
    "            model = algorithm(max_depth = v_max_depth,\n",
    "                              n_estimators = n_estimator,\n",
    "                              random_state=1234)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 최대 깊이에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'depth': para_depth, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 최대 깊이에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_depth, train_score, test_score, \"The number of depth\", \"n_depth\")\n",
    "    print(round(df_score_n, 4))\n",
    "    \n",
    "def optimi_minsplit (algorithm, algorithm_name, X_train, y_train, X_test, y_test, n_split_min, n_split_max, n_estimator, n_depth):\n",
    "    train_score = []; test_score = []\n",
    "    para_split = [n_split*2 for n_split in range(n_split_min, n_split_max)]\n",
    "    for v_min_samples_split in para_split:\n",
    "        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "        if algorithm == DTC:\n",
    "            model = algorithm(min_samples_split = v_min_samples_split,\n",
    "                              max_depth = n_depth,\n",
    "                              random_state = 1234)\n",
    "        else:\n",
    "            model = algorithm(min_samples_split = v_min_samples_split,\n",
    "                              n_estimators = n_estimator,\n",
    "                              max_depth = n_depth,\n",
    "                              random_state = 1234)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 분리 노드의 최소 자료 수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'min_samples_split': para_split, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 분리 노드의 최소 자료 수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_split, train_score, test_score, \"The minimum number of samples required to split an internal node\", \"min_samples_split\")\n",
    "    print(round(df_score_n, 4))\n",
    "    \n",
    "def optimi_minleaf(algorithm, algorithm_name, X_train, y_train, X_test, y_test, n_leaf_min, n_leaf_max, n_estimator, n_depth, n_split):\n",
    "    train_score = []; test_score = []\n",
    "    para_leaf = [n_leaf*2 for n_leaf in range(n_leaf_min, n_leaf_max)]\n",
    "\n",
    "    for v_min_samples_leaf in para_leaf:\n",
    "        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "        if algorithm == DTC:\n",
    "            model = algorithm(min_samples_leaf = v_min_samples_leaf,\n",
    "                                        max_depth = n_depth,\n",
    "                                        min_samples_split = n_split,\n",
    "                                        random_state=1234)\n",
    "        else:\n",
    "            model = algorithm(min_samples_leaf = v_min_samples_leaf,\n",
    "                                n_estimators = n_estimator,\n",
    "                                max_depth = n_depth,\n",
    "                                min_samples_split = n_split,\n",
    "                                random_state=1234)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 잎사귀 노드의 최소 자료 수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'min_samples_leaf': para_leaf, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 잎사귀 노드의 최소 자료 수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_leaf, train_score, test_score, \"The minimum number of samples required to be at a leaf node\", \"min_samples_leaf\")\n",
    "    print(round(df_score_n, 4))\n",
    "    \n",
    "def model_final(algorithm, algorithm_name, feature_name, X_train, y_train, X_test, y_test, n_estimator, n_depth, n_split, n_leaf, selection):\n",
    "    # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "    if algorithm == DTC:\n",
    "        model = algorithm(random_state=1234, \n",
    "                          min_samples_leaf = n_leaf,\n",
    "                          min_samples_split = n_split, \n",
    "                          max_depth = n_depth)\n",
    "    else:\n",
    "        model = algorithm(random_state = 1234, \n",
    "                          n_estimators = n_estimator, \n",
    "                          min_samples_leaf = n_leaf,\n",
    "                          min_samples_split = n_split, \n",
    "                          max_depth = n_depth)\n",
    "    \n",
    "    if selection == 1 :\n",
    "        selector = RFECV(model, min_features_to_select=5, step=1, cv = 5)\n",
    "        selector.fit(X_train, y_train)\n",
    "        selected_columns = X.columns[selector.support_]\n",
    "\n",
    "        print(selected_columns)\n",
    "        train_acc = selector.score(X_train, y_train)\n",
    "        test_acc = selector.score(X_test, y_test)\n",
    "        y_pred = selector.predict(X_test)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, selector.predict_proba(X_test)[:,1])\n",
    "        print('AUC: {}'.format(roc_auc))\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\") # 정확도\n",
    "        print(f\"Precision: {precision_score(y_test, y_pred):.3f}\") # 정밀도\n",
    "        print(f\"Recall: {recall_score(y_test, y_pred):.3f}\") # 재현율\n",
    "        print(f\"F1-score: {f1_score(y_test, y_pred):.3f}\") # F1 스코어\n",
    "\n",
    "        # 혼동행렬 시각화\n",
    "#         plt.figure(figsize =(40, 40))\n",
    "#         plot_confusion_matrix(model, X_test, y_test,include_values = True,display_labels = ['non-negative', 'negative'],cmap = 'Pastel1') # 컬러맵\n",
    "#         plt.show()\n",
    "\n",
    "        # 변수 중요도 산출\n",
    "        dt_importance = pd.DataFrame()\n",
    "        dt_importance['Feature'] = feature_name # 설명변수 이름\n",
    "        dt_importance['Rank'] = selector.ranking_ # 설명변수 중요도 산출\n",
    "\n",
    "        # 변수 중요도 내림차순 정렬\n",
    "        dt_importance.sort_values(\"Rank\", ascending = False, inplace = True)\n",
    "        print(dt_importance.round(3))\n",
    "        # 변수 중요도 오름차순 정렬\n",
    "        dt_importance.sort_values(\"Rank\", ascending = True, inplace = True)\n",
    "        # 변수 중요도 시각화\n",
    "        coordinates = range(len(dt_importance)) # 설명변수 개수만큼 bar 시각화\n",
    "        plt.barh(y = coordinates, width = dt_importance[\"Rank\"])\n",
    "        plt.yticks(coordinates, dt_importance[\"Feature\"]) # y축 눈금별 설명변수 이름 기입\n",
    "        plt.xlabel(\"Feature Rank\") # x축 이름\n",
    "        plt.ylabel(\"Features\") # y축 이름\n",
    "    elif selection == 2:\n",
    "        mi_score = mutual_info_classif(X,y)\n",
    "        print(mi_score)\n",
    "        selector = SelectKBest(mutual_info_classif, k=12)\n",
    "        selector.fit(X_train, y_train)\n",
    "        X_train = selector.transform(X_train)\n",
    "        X_test = selector.transform(X_test)\n",
    "        filter = selector.get_support()\n",
    "        features = array(feature_name)\n",
    "        print(features[filter])\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        score=selector.scores_\n",
    "        \n",
    "        train_acc = model.score(X_train, y_train)\n",
    "        test_acc = model.score(X_test, y_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "        print('AUC: {}'.format(roc_auc))\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\") # 정확도\n",
    "        print(f\"Precision: {precision_score(y_test, y_pred):.3f}\") # 정밀도\n",
    "        print(f\"Recall: {recall_score(y_test, y_pred):.3f}\") # 재현율\n",
    "        print(f\"F1-score: {f1_score(y_test, y_pred):.3f}\") # F1 스코어\n",
    "\n",
    "        # 혼동행렬 시각화\n",
    "        plt.figure(figsize =(40, 40))\n",
    "        plot_confusion_matrix(model, X_test, y_test,include_values = True,display_labels = ['non-negative', 'negative'],cmap = 'Pastel1') # 컬러맵\n",
    "        plt.show()\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "        # 최종 모델의 성능 평가\n",
    "        train_acc = model.score(X_train, y_train)\n",
    "        test_acc = model.score(X_test, y_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "        print('AUC: {}'.format(roc_auc))\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\") # 정확도\n",
    "        print(f\"Precision: {precision_score(y_test, y_pred):.3f}\") # 정밀도\n",
    "        print(f\"Recall: {recall_score(y_test, y_pred):.3f}\") # 재현율\n",
    "        print(f\"F1-score: {f1_score(y_test, y_pred):.3f}\") # F1 스코어\n",
    "\n",
    "        # 혼동행렬 시각화\n",
    "        plt.figure(figsize =(40, 40))\n",
    "        plot_confusion_matrix(model, X_test, y_test,include_values = True,display_labels = ['non-negative', 'negative'],cmap = 'Pastel1') # 컬러맵\n",
    "        plt.show()\n",
    "\n",
    "        # 변수 중요도 산출\n",
    "        dt_importance = pd.DataFrame()\n",
    "        dt_importance['Feature'] = feature_name # 설명변수 이름\n",
    "        dt_importance['Importance'] = model.feature_importances_ # 설명변수 중요도 산출\n",
    "\n",
    "        # 변수 중요도 내림차순 정렬\n",
    "        dt_importance.sort_values(\"Importance\", ascending = False, inplace = True)\n",
    "        print(dt_importance.round(3))\n",
    "        # 변수 중요도 오름차순 정렬\n",
    "        dt_importance.sort_values(\"Importance\", ascending = True, inplace = True)\n",
    "        # 변수 중요도 시각화\n",
    "        coordinates = range(len(dt_importance)) # 설명변수 개수만큼 bar 시각화\n",
    "        plt.barh(y = coordinates, width = dt_importance[\"Importance\"])\n",
    "        plt.yticks(coordinates, dt_importance[\"Feature\"]) # y축 눈금별 설명변수 이름 기입\n",
    "        plt.xlabel(\"Feature Importance\") # x축 이름\n",
    "        plt.ylabel(\"Features\") # y축 이름\n",
    "        \n",
    "    \n",
    "\n",
    "algorithm = GBC\n",
    "algorithm_name = 'gbc'\n",
    "train_acc_before, test_acc_before = modeling_uncustomized(algorithm, \n",
    "                                                          X_train,\n",
    "                                                          y_train,\n",
    "                                                          X_test,\n",
    "                                                          y_test)\n",
    "\n",
    "n_estimator = 145\n",
    "n_depth = 9\n",
    "n_split = 22\n",
    "n_leaf = 4\n",
    "\n",
    "model_final(algorithm, algorithm_name, feature_name,\n",
    "            X_train, y_train, X_test, y_test,\n",
    "            n_estimator, n_depth, n_split, n_leaf,selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95749e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    834\n",
      "1    834\n",
      "Name: sentiment, dtype: int64\n",
      "학습 데이터셋 정확도: 0.872\n",
      "테스트 데이터셋 정확도: 0.784\n",
      "[0.18128336 0.00512499 0.08995579 0.09168819 0.18854404 0.16664706\n",
      " 0.20219446 0.0109063  0.         0.00661828 0.00605652 0.01037725\n",
      " 0.0020636  0.00070095 0.00704314 0.         0.04923145 0.01920274\n",
      " 0.02738431 0.03954573 0.00585544 0.02861927]\n",
      "['Game_Runtime' 'Hunger_PLAYER' 'Health_PLAYER' 'Sanity_PLAYER'\n",
      " 'Player_Xloc' 'Player_Zloc' 'Curr_Equip_Hands_PLAYER' 'Distance' 'log_P'\n",
      " 'grass_P' 'twig_P' 'flint_P']\n",
      "AUC: 0.9725790274871575\n",
      "Accuracy: 0.909\n",
      "Precision: 0.716\n",
      "Recall: 0.961\n",
      "F1-score: 0.821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x2880 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#KOR 3sec - feature selection(2) - under sampling(1/3) + SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "import warnings; warnings.filterwarnings(action='ignore') # 경고 메시지 무시\n",
    "import matplotlib.pyplot as plt # 데이터 시각화 라이브러리\n",
    "import pickle # 객체 입출력을 위한 라이브러리\n",
    "from sklearn.model_selection import train_test_split # 훈련 데이터, 테스트 데이터 분리\n",
    "from sklearn.preprocessing import StandardScaler # 정규화\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC # 랜덤포레스트 분류 알고리즘\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC # 의사결정나무 분류 알고리즘\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC # 그래디언트 부스팅 분류 알고리즘\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, plot_confusion_matrix\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from numpy import array \n",
    "########################\n",
    "\n",
    "UnderSampling = 1       # 1 : undersampling(size->1/3), 2 : undersampling(size->minority),   0 : not undersampling    \n",
    "OverSampling = 1        # 1 : oversampling(SMOTE),                                           0 : not oversampling\n",
    "selection = 2           # 1 : feature selection - RFEVC, 2 : feature selection - mutual information, 0 : not feature selection\n",
    "feat_start=1\n",
    "########################\n",
    "data = pd.read_csv('/Users/jun/Data/sentiment analysis - KOR/5초전데이터/sentiment+gamedata/KOR-3sec(fin).csv')\n",
    "scaler = StandardScaler()\n",
    "y = data['sentiment']\n",
    "X = data.drop(labels=['sentiment','file','time'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,random_state=7)\n",
    "# 설명변수 데이터 스케일링\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "feature_name = X.columns\n",
    "if UnderSampling == 1:\n",
    "    undersample = RandomUnderSampler(sampling_strategy=0.836) \n",
    "    X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "elif UnderSampling == 2:\n",
    "    undersample = RandomUnderSampler(sampling_strategy='majority') \n",
    "    X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "    \n",
    "if OverSampling == 1:\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    \n",
    "print(y_train.value_counts())\n",
    "\n",
    "def modeling_uncustomized (algorithm, X_train, y_train, X_test, y_test):\n",
    "    # 하이퍼파라미터 조정 없이 모델 학습\n",
    "    uncustomized = algorithm(random_state=1234)\n",
    "    uncustomized.fit(X_train, y_train)\n",
    "    # Train Data 설명력\n",
    "    train_score_before = uncustomized.score(X_train, y_train).round(3)\n",
    "    print(f\"학습 데이터셋 정확도: {train_score_before}\")\n",
    "    # Test Data 설명력\n",
    "    test_score_before = uncustomized.score(X_test, y_test).round(3)\n",
    "    print(f\"테스트 데이터셋 정확도: {test_score_before}\")\n",
    "    return train_score_before, test_score_before\n",
    "\n",
    "\n",
    "def optimi_visualization(algorithm_name, X_values, train_score, test_score, xlabel, filename):\n",
    "    # 하이퍼파라미터 조정에 따른 학습 데이터셋 기반 모델 성능 추이 시각화\n",
    "    plt.plot(X_values, train_score, linestyle = '-', label = 'train score')\n",
    "    # 하이퍼파라미터 조정에 따른 테스트 데이터셋 기반 모델 성능 추이 시각화\n",
    "    plt.plot(X_values, test_score, linestyle = '--', label = 'test score')\n",
    "    plt.ylabel('Accuracy(%)') # y축 라벨\n",
    "    plt.xlabel(xlabel) # x축 라벨\n",
    "    plt.legend() # 범례표시\n",
    "    \n",
    "def optimi_estimator(algorithm, algorithm_name, X_train, y_train, X_test, y_test, n_estimator_min, n_estimator_max):\n",
    "    train_score = []; test_score =[]\n",
    "    para_n_tree = [n_tree*5 for n_tree in range(n_estimator_min, n_estimator_max)]\n",
    "\n",
    "    for v_n_estimators in para_n_tree:\n",
    "        model = algorithm(n_estimators = v_n_estimators, random_state=1234)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 트리 개수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'n_estimators': para_n_tree, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 트리 개수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_n_tree, train_score, test_score, \"The number of estimator\", \"n_estimator\")\n",
    "    print(round(df_score_n, 4))\n",
    "\n",
    "\n",
    "def optimi_maxdepth (algorithm, algorithm_name, X_train, y_train, X_test, y_test, depth_min, depth_max, n_estimator):\n",
    "    train_score = []; test_score = []\n",
    "    para_depth = [depth for depth in range(depth_min, depth_max)]\n",
    "\n",
    "    for v_max_depth in para_depth:\n",
    "        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "        if algorithm == DTC:\n",
    "            model = algorithm(max_depth = v_max_depth,\n",
    "                              random_state=1234)\n",
    "        else:\n",
    "            model = algorithm(max_depth = v_max_depth,\n",
    "                              n_estimators = n_estimator,\n",
    "                              random_state=1234)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 최대 깊이에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'depth': para_depth, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 최대 깊이에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_depth, train_score, test_score, \"The number of depth\", \"n_depth\")\n",
    "    print(round(df_score_n, 4))\n",
    "    \n",
    "def optimi_minsplit (algorithm, algorithm_name, X_train, y_train, X_test, y_test, n_split_min, n_split_max, n_estimator, n_depth):\n",
    "    train_score = []; test_score = []\n",
    "    para_split = [n_split*2 for n_split in range(n_split_min, n_split_max)]\n",
    "    for v_min_samples_split in para_split:\n",
    "        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "        if algorithm == DTC:\n",
    "            model = algorithm(min_samples_split = v_min_samples_split,\n",
    "                              max_depth = n_depth,\n",
    "                              random_state = 1234)\n",
    "        else:\n",
    "            model = algorithm(min_samples_split = v_min_samples_split,\n",
    "                              n_estimators = n_estimator,\n",
    "                              max_depth = n_depth,\n",
    "                              random_state = 1234)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 분리 노드의 최소 자료 수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'min_samples_split': para_split, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 분리 노드의 최소 자료 수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_split, train_score, test_score, \"The minimum number of samples required to split an internal node\", \"min_samples_split\")\n",
    "    print(round(df_score_n, 4))\n",
    "    \n",
    "def optimi_minleaf(algorithm, algorithm_name, X_train, y_train, X_test, y_test, n_leaf_min, n_leaf_max, n_estimator, n_depth, n_split):\n",
    "    train_score = []; test_score = []\n",
    "    para_leaf = [n_leaf*2 for n_leaf in range(n_leaf_min, n_leaf_max)]\n",
    "\n",
    "    for v_min_samples_leaf in para_leaf:\n",
    "        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "        if algorithm == DTC:\n",
    "            model = algorithm(min_samples_leaf = v_min_samples_leaf,\n",
    "                                        max_depth = n_depth,\n",
    "                                        min_samples_split = n_split,\n",
    "                                        random_state=1234)\n",
    "        else:\n",
    "            model = algorithm(min_samples_leaf = v_min_samples_leaf,\n",
    "                                n_estimators = n_estimator,\n",
    "                                max_depth = n_depth,\n",
    "                                min_samples_split = n_split,\n",
    "                                random_state=1234)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 잎사귀 노드의 최소 자료 수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'min_samples_leaf': para_leaf, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 잎사귀 노드의 최소 자료 수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_leaf, train_score, test_score, \"The minimum number of samples required to be at a leaf node\", \"min_samples_leaf\")\n",
    "    print(round(df_score_n, 4))\n",
    "    \n",
    "def model_final(algorithm, algorithm_name, feature_name, X_train, y_train, X_test, y_test, n_estimator, n_depth, n_split, n_leaf, selection):\n",
    "    # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "    if algorithm == DTC:\n",
    "        model = algorithm(random_state=1234, \n",
    "                          min_samples_leaf = n_leaf,\n",
    "                          min_samples_split = n_split, \n",
    "                          max_depth = n_depth)\n",
    "    else:\n",
    "        model = algorithm(random_state = 1234, \n",
    "                          n_estimators = n_estimator, \n",
    "                          min_samples_leaf = n_leaf,\n",
    "                          min_samples_split = n_split, \n",
    "                          max_depth = n_depth)\n",
    "    \n",
    "    if selection == 1 :\n",
    "        selector = RFECV(model, min_features_to_select=5, step=1, cv = 5)\n",
    "        selector.fit(X_train, y_train)\n",
    "        selected_columns = X.columns[selector.support_]\n",
    "\n",
    "        print(selected_columns)\n",
    "        train_acc = selector.score(X_train, y_train)\n",
    "        test_acc = selector.score(X_test, y_test)\n",
    "        y_pred = selector.predict(X_test)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, selector.predict_proba(X_test)[:,1])\n",
    "        print('AUC: {}'.format(roc_auc))\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\") # 정확도\n",
    "        print(f\"Precision: {precision_score(y_test, y_pred):.3f}\") # 정밀도\n",
    "        print(f\"Recall: {recall_score(y_test, y_pred):.3f}\") # 재현율\n",
    "        print(f\"F1-score: {f1_score(y_test, y_pred):.3f}\") # F1 스코어\n",
    "\n",
    "        # 혼동행렬 시각화\n",
    "#         plt.figure(figsize =(40, 40))\n",
    "#         plot_confusion_matrix(model, X_test, y_test,include_values = True,display_labels = ['non-negative', 'negative'],cmap = 'Pastel1') # 컬러맵\n",
    "#         plt.show()\n",
    "\n",
    "        # 변수 중요도 산출\n",
    "        dt_importance = pd.DataFrame()\n",
    "        dt_importance['Feature'] = feature_name # 설명변수 이름\n",
    "        dt_importance['Rank'] = selector.ranking_ # 설명변수 중요도 산출\n",
    "\n",
    "        # 변수 중요도 내림차순 정렬\n",
    "        dt_importance.sort_values(\"Rank\", ascending = False, inplace = True)\n",
    "        print(dt_importance.round(3))\n",
    "        # 변수 중요도 오름차순 정렬\n",
    "        dt_importance.sort_values(\"Rank\", ascending = True, inplace = True)\n",
    "        # 변수 중요도 시각화\n",
    "        coordinates = range(len(dt_importance)) # 설명변수 개수만큼 bar 시각화\n",
    "        plt.barh(y = coordinates, width = dt_importance[\"Rank\"])\n",
    "        plt.yticks(coordinates, dt_importance[\"Feature\"]) # y축 눈금별 설명변수 이름 기입\n",
    "        plt.xlabel(\"Feature Rank\") # x축 이름\n",
    "        plt.ylabel(\"Features\") # y축 이름\n",
    "    elif selection == 2:\n",
    "        mi_score = mutual_info_classif(X,y)\n",
    "        print(mi_score)\n",
    "        selector = SelectKBest(mutual_info_classif, k=12)\n",
    "        selector.fit(X_train, y_train)\n",
    "        X_train = selector.transform(X_train)\n",
    "        X_test = selector.transform(X_test)\n",
    "        filter = selector.get_support()\n",
    "        features = array(feature_name)\n",
    "        print(features[filter])\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        score=selector.scores_\n",
    "        \n",
    "        train_acc = model.score(X_train, y_train)\n",
    "        test_acc = model.score(X_test, y_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "        print('AUC: {}'.format(roc_auc))\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\") # 정확도\n",
    "        print(f\"Precision: {precision_score(y_test, y_pred):.3f}\") # 정밀도\n",
    "        print(f\"Recall: {recall_score(y_test, y_pred):.3f}\") # 재현율\n",
    "        print(f\"F1-score: {f1_score(y_test, y_pred):.3f}\") # F1 스코어\n",
    "\n",
    "        # 혼동행렬 시각화\n",
    "        plt.figure(figsize =(40, 40))\n",
    "        plot_confusion_matrix(model, X_test, y_test,include_values = True,display_labels = ['non-negative', 'negative'],cmap = 'Pastel1') # 컬러맵\n",
    "        plt.show()\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "        # 최종 모델의 성능 평가\n",
    "        train_acc = model.score(X_train, y_train)\n",
    "        test_acc = model.score(X_test, y_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "        print('AUC: {}'.format(roc_auc))\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\") # 정확도\n",
    "        print(f\"Precision: {precision_score(y_test, y_pred):.3f}\") # 정밀도\n",
    "        print(f\"Recall: {recall_score(y_test, y_pred):.3f}\") # 재현율\n",
    "        print(f\"F1-score: {f1_score(y_test, y_pred):.3f}\") # F1 스코어\n",
    "\n",
    "        # 혼동행렬 시각화\n",
    "        plt.figure(figsize =(40, 40))\n",
    "        plot_confusion_matrix(model, X_test, y_test,include_values = True,display_labels = ['non-negative', 'negative'],cmap = 'Pastel1') # 컬러맵\n",
    "        plt.show()\n",
    "\n",
    "        # 변수 중요도 산출\n",
    "        dt_importance = pd.DataFrame()\n",
    "        dt_importance['Feature'] = feature_name # 설명변수 이름\n",
    "        dt_importance['Importance'] = model.feature_importances_ # 설명변수 중요도 산출\n",
    "\n",
    "        # 변수 중요도 내림차순 정렬\n",
    "        dt_importance.sort_values(\"Importance\", ascending = False, inplace = True)\n",
    "        print(dt_importance.round(3))\n",
    "        # 변수 중요도 오름차순 정렬\n",
    "        dt_importance.sort_values(\"Importance\", ascending = True, inplace = True)\n",
    "        # 변수 중요도 시각화\n",
    "        coordinates = range(len(dt_importance)) # 설명변수 개수만큼 bar 시각화\n",
    "        plt.barh(y = coordinates, width = dt_importance[\"Importance\"])\n",
    "        plt.yticks(coordinates, dt_importance[\"Feature\"]) # y축 눈금별 설명변수 이름 기입\n",
    "        plt.xlabel(\"Feature Importance\") # x축 이름\n",
    "        plt.ylabel(\"Features\") # y축 이름\n",
    "        \n",
    "    \n",
    "\n",
    "algorithm = GBC\n",
    "algorithm_name = 'gbc'\n",
    "train_acc_before, test_acc_before = modeling_uncustomized(algorithm, \n",
    "                                                          X_train,\n",
    "                                                          y_train,\n",
    "                                                          X_test,\n",
    "                                                          y_test)\n",
    "\n",
    "n_estimator = 140\n",
    "n_depth = 12\n",
    "n_split = 24\n",
    "n_leaf = 42\n",
    "\n",
    "model_final(algorithm, algorithm_name, feature_name,\n",
    "            X_train, y_train, X_test, y_test,\n",
    "            n_estimator, n_depth, n_split, n_leaf,selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a0b9309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2977\n",
      "1    2977\n",
      "Name: sentiment, dtype: int64\n",
      "학습 데이터셋 정확도: 0.871\n",
      "테스트 데이터셋 정확도: 0.809\n",
      "[0.05257941 0.00033085 0.02483902 0.02134086 0.05908079 0.07152617\n",
      " 0.06545096 0.00374581 0.00154551 0.00014452 0.         0.00044384\n",
      " 0.         0.0039329  0.00106184 0.         0.02031124 0.00234242\n",
      " 0.00345484 0.00350704 0.00204696 0.00440261]\n",
      "['Game_Runtime' 'Hunger_PLAYER' 'Health_PLAYER' 'Sanity_PLAYER'\n",
      " 'Player_Xloc' 'Player_Zloc' 'Curr_Inv_Cnt_PLAYER' 'Distance' 'log_P'\n",
      " 'grass_P' 'twig_P' 'flint_P']\n",
      "AUC: 0.983238159220692\n",
      "Accuracy: 0.955\n",
      "Precision: 0.547\n",
      "Recall: 0.929\n",
      "F1-score: 0.688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x2880 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ENG 3sec - feature selection(2) - under sampling(1/3) + SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "import warnings; warnings.filterwarnings(action='ignore') # 경고 메시지 무시\n",
    "import matplotlib.pyplot as plt # 데이터 시각화 라이브러리\n",
    "import pickle # 객체 입출력을 위한 라이브러리\n",
    "from sklearn.model_selection import train_test_split # 훈련 데이터, 테스트 데이터 분리\n",
    "from sklearn.preprocessing import StandardScaler # 정규화\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC # 랜덤포레스트 분류 알고리즘\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC # 의사결정나무 분류 알고리즘\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC # 그래디언트 부스팅 분류 알고리즘\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, plot_confusion_matrix\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from numpy import array \n",
    "########################\n",
    "\n",
    "UnderSampling = 1       # 1 : undersampling(size->1/3), 2 : undersampling(size->minority),   0 : not undersampling    \n",
    "OverSampling = 1        # 1 : oversampling(SMOTE),                                           0 : not oversampling\n",
    "selection = 2           # 1 : feature selection - RFEVC, 2 : feature selection - mutual information, 0 : not feature selection\n",
    "feat_start=1\n",
    "########################\n",
    "data = pd.read_csv('/Users/jun/Data/sentiment analysis - ENG/5초전/사용할 파일/sentiment+gamedata/ENG-3sec(fin).csv')\n",
    "scaler = StandardScaler()\n",
    "y = data['sentiment']\n",
    "X = data.drop(labels=['sentiment','file','time'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,random_state=7)\n",
    "# 설명변수 데이터 스케일링\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "feature_name = X.columns\n",
    "if UnderSampling == 1:\n",
    "    undersample = RandomUnderSampler(sampling_strategy=0.17064) \n",
    "    X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "elif UnderSampling == 2:\n",
    "    undersample = RandomUnderSampler(sampling_strategy='majority') \n",
    "    X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "    \n",
    "if OverSampling == 1:\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    \n",
    "print(y_train.value_counts())\n",
    "\n",
    "def modeling_uncustomized (algorithm, X_train, y_train, X_test, y_test):\n",
    "    # 하이퍼파라미터 조정 없이 모델 학습\n",
    "    uncustomized = algorithm(random_state=1234)\n",
    "    uncustomized.fit(X_train, y_train)\n",
    "    # Train Data 설명력\n",
    "    train_score_before = uncustomized.score(X_train, y_train).round(3)\n",
    "    print(f\"학습 데이터셋 정확도: {train_score_before}\")\n",
    "    # Test Data 설명력\n",
    "    test_score_before = uncustomized.score(X_test, y_test).round(3)\n",
    "    print(f\"테스트 데이터셋 정확도: {test_score_before}\")\n",
    "    return train_score_before, test_score_before\n",
    "\n",
    "\n",
    "def optimi_visualization(algorithm_name, X_values, train_score, test_score, xlabel, filename):\n",
    "    # 하이퍼파라미터 조정에 따른 학습 데이터셋 기반 모델 성능 추이 시각화\n",
    "    plt.plot(X_values, train_score, linestyle = '-', label = 'train score')\n",
    "    # 하이퍼파라미터 조정에 따른 테스트 데이터셋 기반 모델 성능 추이 시각화\n",
    "    plt.plot(X_values, test_score, linestyle = '--', label = 'test score')\n",
    "    plt.ylabel('Accuracy(%)') # y축 라벨\n",
    "    plt.xlabel(xlabel) # x축 라벨\n",
    "    plt.legend() # 범례표시\n",
    "    \n",
    "def optimi_estimator(algorithm, algorithm_name, X_train, y_train, X_test, y_test, n_estimator_min, n_estimator_max):\n",
    "    train_score = []; test_score =[]\n",
    "    para_n_tree = [n_tree*5 for n_tree in range(n_estimator_min, n_estimator_max)]\n",
    "\n",
    "    for v_n_estimators in para_n_tree:\n",
    "        model = algorithm(n_estimators = v_n_estimators, random_state=1234)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 트리 개수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'n_estimators': para_n_tree, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 트리 개수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_n_tree, train_score, test_score, \"The number of estimator\", \"n_estimator\")\n",
    "    print(round(df_score_n, 4))\n",
    "\n",
    "\n",
    "def optimi_maxdepth (algorithm, algorithm_name, X_train, y_train, X_test, y_test, depth_min, depth_max, n_estimator):\n",
    "    train_score = []; test_score = []\n",
    "    para_depth = [depth for depth in range(depth_min, depth_max)]\n",
    "\n",
    "    for v_max_depth in para_depth:\n",
    "        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "        if algorithm == DTC:\n",
    "            model = algorithm(max_depth = v_max_depth,\n",
    "                              random_state=1234)\n",
    "        else:\n",
    "            model = algorithm(max_depth = v_max_depth,\n",
    "                              n_estimators = n_estimator,\n",
    "                              random_state=1234)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 최대 깊이에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'depth': para_depth, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 최대 깊이에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_depth, train_score, test_score, \"The number of depth\", \"n_depth\")\n",
    "    print(round(df_score_n, 4))\n",
    "    \n",
    "def optimi_minsplit (algorithm, algorithm_name, X_train, y_train, X_test, y_test, n_split_min, n_split_max, n_estimator, n_depth):\n",
    "    train_score = []; test_score = []\n",
    "    para_split = [n_split*2 for n_split in range(n_split_min, n_split_max)]\n",
    "    for v_min_samples_split in para_split:\n",
    "        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "        if algorithm == DTC:\n",
    "            model = algorithm(min_samples_split = v_min_samples_split,\n",
    "                              max_depth = n_depth,\n",
    "                              random_state = 1234)\n",
    "        else:\n",
    "            model = algorithm(min_samples_split = v_min_samples_split,\n",
    "                              n_estimators = n_estimator,\n",
    "                              max_depth = n_depth,\n",
    "                              random_state = 1234)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 분리 노드의 최소 자료 수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'min_samples_split': para_split, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 분리 노드의 최소 자료 수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_split, train_score, test_score, \"The minimum number of samples required to split an internal node\", \"min_samples_split\")\n",
    "    print(round(df_score_n, 4))\n",
    "    \n",
    "def optimi_minleaf(algorithm, algorithm_name, X_train, y_train, X_test, y_test, n_leaf_min, n_leaf_max, n_estimator, n_depth, n_split):\n",
    "    train_score = []; test_score = []\n",
    "    para_leaf = [n_leaf*2 for n_leaf in range(n_leaf_min, n_leaf_max)]\n",
    "\n",
    "    for v_min_samples_leaf in para_leaf:\n",
    "        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "        if algorithm == DTC:\n",
    "            model = algorithm(min_samples_leaf = v_min_samples_leaf,\n",
    "                                        max_depth = n_depth,\n",
    "                                        min_samples_split = n_split,\n",
    "                                        random_state=1234)\n",
    "        else:\n",
    "            model = algorithm(min_samples_leaf = v_min_samples_leaf,\n",
    "                                n_estimators = n_estimator,\n",
    "                                max_depth = n_depth,\n",
    "                                min_samples_split = n_split,\n",
    "                                random_state=1234)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 잎사귀 노드의 최소 자료 수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'min_samples_leaf': para_leaf, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 잎사귀 노드의 최소 자료 수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_leaf, train_score, test_score, \"The minimum number of samples required to be at a leaf node\", \"min_samples_leaf\")\n",
    "    print(round(df_score_n, 4))\n",
    "    \n",
    "def model_final(algorithm, algorithm_name, feature_name, X_train, y_train, X_test, y_test, n_estimator, n_depth, n_split, n_leaf, selection):\n",
    "    # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "    if algorithm == DTC:\n",
    "        model = algorithm(random_state=1234, \n",
    "                          min_samples_leaf = n_leaf,\n",
    "                          min_samples_split = n_split, \n",
    "                          max_depth = n_depth)\n",
    "    else:\n",
    "        model = algorithm(random_state = 1234, \n",
    "                          n_estimators = n_estimator, \n",
    "                          min_samples_leaf = n_leaf,\n",
    "                          min_samples_split = n_split, \n",
    "                          max_depth = n_depth)\n",
    "    \n",
    "    if selection == 1 :\n",
    "        selector = RFECV(model, min_features_to_select=5, step=1, cv = 5)\n",
    "        selector.fit(X_train, y_train)\n",
    "        selected_columns = X.columns[selector.support_]\n",
    "\n",
    "        print(selected_columns)\n",
    "        train_acc = selector.score(X_train, y_train)\n",
    "        test_acc = selector.score(X_test, y_test)\n",
    "        y_pred = selector.predict(X_test)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, selector.predict_proba(X_test)[:,1])\n",
    "        print('AUC: {}'.format(roc_auc))\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\") # 정확도\n",
    "        print(f\"Precision: {precision_score(y_test, y_pred):.3f}\") # 정밀도\n",
    "        print(f\"Recall: {recall_score(y_test, y_pred):.3f}\") # 재현율\n",
    "        print(f\"F1-score: {f1_score(y_test, y_pred):.3f}\") # F1 스코어\n",
    "\n",
    "        # 혼동행렬 시각화\n",
    "#         plt.figure(figsize =(40, 40))\n",
    "#         plot_confusion_matrix(model, X_test, y_test,include_values = True,display_labels = ['non-negative', 'negative'],cmap = 'Pastel1') # 컬러맵\n",
    "#         plt.show()\n",
    "\n",
    "        # 변수 중요도 산출\n",
    "        dt_importance = pd.DataFrame()\n",
    "        dt_importance['Feature'] = feature_name # 설명변수 이름\n",
    "        dt_importance['Rank'] = selector.ranking_ # 설명변수 중요도 산출\n",
    "\n",
    "        # 변수 중요도 내림차순 정렬\n",
    "        dt_importance.sort_values(\"Rank\", ascending = False, inplace = True)\n",
    "        print(dt_importance.round(3))\n",
    "        # 변수 중요도 오름차순 정렬\n",
    "        dt_importance.sort_values(\"Rank\", ascending = True, inplace = True)\n",
    "        # 변수 중요도 시각화\n",
    "        coordinates = range(len(dt_importance)) # 설명변수 개수만큼 bar 시각화\n",
    "        plt.barh(y = coordinates, width = dt_importance[\"Rank\"])\n",
    "        plt.yticks(coordinates, dt_importance[\"Feature\"]) # y축 눈금별 설명변수 이름 기입\n",
    "        plt.xlabel(\"Feature Rank\") # x축 이름\n",
    "        plt.ylabel(\"Features\") # y축 이름\n",
    "    elif selection == 2:\n",
    "        mi_score = mutual_info_classif(X,y)\n",
    "        print(mi_score)\n",
    "        selector = SelectKBest(mutual_info_classif, k=12)\n",
    "        selector.fit(X_train, y_train)\n",
    "        X_train = selector.transform(X_train)\n",
    "        X_test = selector.transform(X_test)\n",
    "        filter = selector.get_support()\n",
    "        features = array(feature_name)\n",
    "        print(features[filter])\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        score=selector.scores_\n",
    "        \n",
    "        train_acc = model.score(X_train, y_train)\n",
    "        test_acc = model.score(X_test, y_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "        print('AUC: {}'.format(roc_auc))\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\") # 정확도\n",
    "        print(f\"Precision: {precision_score(y_test, y_pred):.3f}\") # 정밀도\n",
    "        print(f\"Recall: {recall_score(y_test, y_pred):.3f}\") # 재현율\n",
    "        print(f\"F1-score: {f1_score(y_test, y_pred):.3f}\") # F1 스코어\n",
    "\n",
    "        # 혼동행렬 시각화\n",
    "        plt.figure(figsize =(40, 40))\n",
    "        plot_confusion_matrix(model, X_test, y_test,include_values = True,display_labels = ['non-negative', 'negative'],cmap = 'Pastel1') # 컬러맵\n",
    "        plt.show()\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "        # 최종 모델의 성능 평가\n",
    "        train_acc = model.score(X_train, y_train)\n",
    "        test_acc = model.score(X_test, y_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "        print('AUC: {}'.format(roc_auc))\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\") # 정확도\n",
    "        print(f\"Precision: {precision_score(y_test, y_pred):.3f}\") # 정밀도\n",
    "        print(f\"Recall: {recall_score(y_test, y_pred):.3f}\") # 재현율\n",
    "        print(f\"F1-score: {f1_score(y_test, y_pred):.3f}\") # F1 스코어\n",
    "\n",
    "        # 혼동행렬 시각화\n",
    "        plt.figure(figsize =(40, 40))\n",
    "        plot_confusion_matrix(model, X_test, y_test,include_values = True,display_labels = ['non-negative', 'negative'],cmap = 'Pastel1') # 컬러맵\n",
    "        plt.show()\n",
    "\n",
    "        # 변수 중요도 산출\n",
    "        dt_importance = pd.DataFrame()\n",
    "        dt_importance['Feature'] = feature_name # 설명변수 이름\n",
    "        dt_importance['Importance'] = model.feature_importances_ # 설명변수 중요도 산출\n",
    "\n",
    "        # 변수 중요도 내림차순 정렬\n",
    "        dt_importance.sort_values(\"Importance\", ascending = False, inplace = True)\n",
    "        print(dt_importance.round(3))\n",
    "        # 변수 중요도 오름차순 정렬\n",
    "        dt_importance.sort_values(\"Importance\", ascending = True, inplace = True)\n",
    "        # 변수 중요도 시각화\n",
    "        coordinates = range(len(dt_importance)) # 설명변수 개수만큼 bar 시각화\n",
    "        plt.barh(y = coordinates, width = dt_importance[\"Importance\"])\n",
    "        plt.yticks(coordinates, dt_importance[\"Feature\"]) # y축 눈금별 설명변수 이름 기입\n",
    "        plt.xlabel(\"Feature Importance\") # x축 이름\n",
    "        plt.ylabel(\"Features\") # y축 이름\n",
    "        \n",
    "    \n",
    "\n",
    "algorithm = GBC\n",
    "algorithm_name = 'gbc'\n",
    "train_acc_before, test_acc_before = modeling_uncustomized(algorithm, \n",
    "                                                          X_train,\n",
    "                                                          y_train,\n",
    "                                                          X_test,\n",
    "                                                          y_test)\n",
    "\n",
    "n_estimator = 150\n",
    "n_depth = 12\n",
    "n_split = 20\n",
    "n_leaf = 16\n",
    "\n",
    "model_final(algorithm, algorithm_name, feature_name,\n",
    "            X_train, y_train, X_test, y_test,\n",
    "            n_estimator, n_depth, n_split, n_leaf,selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "161cef2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1266\n",
      "1    1266\n",
      "Name: sentiment, dtype: int64\n",
      "학습 데이터셋 정확도: 0.874\n",
      "테스트 데이터셋 정확도: 0.831\n",
      "[0.15067338 0.00114065 0.07229557 0.07816885 0.18874866 0.17357536\n",
      " 0.20499459 0.01846834 0.         0.01099981 0.00289041 0.0125604\n",
      " 0.00158572 0.         0.00572938 0.         0.05528353 0.03203175\n",
      " 0.02682582 0.02896897 0.02206294 0.021932  ]\n",
      "['Game_Runtime' 'Hunger_PLAYER' 'Health_PLAYER' 'Sanity_PLAYER'\n",
      " 'Player_Xloc' 'Player_Zloc' 'rock_P']\n",
      "AUC: 0.9924040454375573\n",
      "Accuracy: 0.953\n",
      "Precision: 0.823\n",
      "Recall: 0.997\n",
      "F1-score: 0.902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x2880 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#KOR 5sec - feature selection(2) - under sampling(1/3) + SMOTE\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from numpy import array \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "import warnings; warnings.filterwarnings(action='ignore') # 경고 메시지 무시\n",
    "import matplotlib.pyplot as plt # 데이터 시각화 라이브러리\n",
    "import pickle # 객체 입출력을 위한 라이브러리\n",
    "from sklearn.model_selection import train_test_split # 훈련 데이터, 테스트 데이터 분리\n",
    "from sklearn.preprocessing import StandardScaler # 정규화\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC # 랜덤포레스트 분류 알고리즘\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC # 의사결정나무 분류 알고리즘\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC # 그래디언트 부스팅 분류 알고리즘\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, plot_confusion_matrix\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "import joblib\n",
    "########################\n",
    "\n",
    "UnderSampling = 1       # 1 : undersampling(size->1/3), 2 : undersampling(size->minority),   0 : not undersampling    \n",
    "OverSampling = 1        # 1 : oversampling(SMOTE),                                           0 : not oversampling\n",
    "selection = 2           # 1 : feature selection - RFEVC, 2 : feature selection - mutual information, 0 : not feature selection\n",
    "feat_start=1\n",
    "########################\n",
    "data = pd.read_csv('/Users/jun/Data/sentiment analysis - KOR/5초전데이터/sentiment+gamedata/KOR-5sec(fin).csv')\n",
    "scaler = StandardScaler()\n",
    "y = data['sentiment']\n",
    "X = data.drop(labels=['sentiment','file','time'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,random_state=7)\n",
    "# 설명변수 데이터 스케일링\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "feature_name = X.columns\n",
    "if UnderSampling == 1:\n",
    "    undersample = RandomUnderSampler(sampling_strategy=0.827) \n",
    "    X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "elif UnderSampling == 2:\n",
    "    undersample = RandomUnderSampler(sampling_strategy='majority') \n",
    "    X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "    \n",
    "if OverSampling == 1:\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    \n",
    "print(y_train.value_counts())\n",
    "\n",
    "def modeling_uncustomized (algorithm, X_train, y_train, X_test, y_test):\n",
    "    # 하이퍼파라미터 조정 없이 모델 학습\n",
    "    uncustomized = algorithm(random_state=1234)\n",
    "    uncustomized.fit(X_train, y_train)\n",
    "    # Train Data 설명력\n",
    "    train_score_before = uncustomized.score(X_train, y_train).round(3)\n",
    "    print(f\"학습 데이터셋 정확도: {train_score_before}\")\n",
    "    # Test Data 설명력\n",
    "    test_score_before = uncustomized.score(X_test, y_test).round(3)\n",
    "    print(f\"테스트 데이터셋 정확도: {test_score_before}\")\n",
    "    return train_score_before, test_score_before\n",
    "\n",
    "\n",
    "def optimi_visualization(algorithm_name, X_values, train_score, test_score, xlabel, filename):\n",
    "    # 하이퍼파라미터 조정에 따른 학습 데이터셋 기반 모델 성능 추이 시각화\n",
    "    plt.plot(X_values, train_score, linestyle = '-', label = 'train score')\n",
    "    # 하이퍼파라미터 조정에 따른 테스트 데이터셋 기반 모델 성능 추이 시각화\n",
    "    plt.plot(X_values, test_score, linestyle = '--', label = 'test score')\n",
    "    plt.ylabel('Accuracy(%)') # y축 라벨\n",
    "    plt.xlabel(xlabel) # x축 라벨\n",
    "    plt.legend() # 범례표시\n",
    "    \n",
    "def optimi_estimator(algorithm, algorithm_name, X_train, y_train, X_test, y_test, n_estimator_min, n_estimator_max):\n",
    "    train_score = []; test_score =[]\n",
    "    para_n_tree = [n_tree*5 for n_tree in range(n_estimator_min, n_estimator_max)]\n",
    "\n",
    "    for v_n_estimators in para_n_tree:\n",
    "        model = algorithm(n_estimators = v_n_estimators, random_state=1234)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 트리 개수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'n_estimators': para_n_tree, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 트리 개수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_n_tree, train_score, test_score, \"The number of estimator\", \"n_estimator\")\n",
    "    print(round(df_score_n, 4))\n",
    "\n",
    "\n",
    "def optimi_maxdepth (algorithm, algorithm_name, X_train, y_train, X_test, y_test, depth_min, depth_max, n_estimator):\n",
    "    train_score = []; test_score = []\n",
    "    para_depth = [depth for depth in range(depth_min, depth_max)]\n",
    "\n",
    "    for v_max_depth in para_depth:\n",
    "        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "        if algorithm == DTC:\n",
    "            model = algorithm(max_depth = v_max_depth,\n",
    "                              random_state=1234)\n",
    "        else:\n",
    "            model = algorithm(max_depth = v_max_depth,\n",
    "                              n_estimators = n_estimator,\n",
    "                              random_state=1234)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 최대 깊이에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'depth': para_depth, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 최대 깊이에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_depth, train_score, test_score, \"The number of depth\", \"n_depth\")\n",
    "    print(round(df_score_n, 4))\n",
    "    \n",
    "def optimi_minsplit (algorithm, algorithm_name, X_train, y_train, X_test, y_test, n_split_min, n_split_max, n_estimator, n_depth):\n",
    "    train_score = []; test_score = []\n",
    "    para_split = [n_split*2 for n_split in range(n_split_min, n_split_max)]\n",
    "    for v_min_samples_split in para_split:\n",
    "        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "        if algorithm == DTC:\n",
    "            model = algorithm(min_samples_split = v_min_samples_split,\n",
    "                              max_depth = n_depth,\n",
    "                              random_state = 1234)\n",
    "        else:\n",
    "            model = algorithm(min_samples_split = v_min_samples_split,\n",
    "                              n_estimators = n_estimator,\n",
    "                              max_depth = n_depth,\n",
    "                              random_state = 1234)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 분리 노드의 최소 자료 수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'min_samples_split': para_split, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 분리 노드의 최소 자료 수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_split, train_score, test_score, \"The minimum number of samples required to split an internal node\", \"min_samples_split\")\n",
    "    print(round(df_score_n, 4))\n",
    "    \n",
    "def optimi_minleaf(algorithm, algorithm_name, X_train, y_train, X_test, y_test, n_leaf_min, n_leaf_max, n_estimator, n_depth, n_split):\n",
    "    train_score = []; test_score = []\n",
    "    para_leaf = [n_leaf*2 for n_leaf in range(n_leaf_min, n_leaf_max)]\n",
    "\n",
    "    for v_min_samples_leaf in para_leaf:\n",
    "        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "        if algorithm == DTC:\n",
    "            model = algorithm(min_samples_leaf = v_min_samples_leaf,\n",
    "                                        max_depth = n_depth,\n",
    "                                        min_samples_split = n_split,\n",
    "                                        random_state=1234)\n",
    "        else:\n",
    "            model = algorithm(min_samples_leaf = v_min_samples_leaf,\n",
    "                                n_estimators = n_estimator,\n",
    "                                max_depth = n_depth,\n",
    "                                min_samples_split = n_split,\n",
    "                                random_state=1234)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 잎사귀 노드의 최소 자료 수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'min_samples_leaf': para_leaf, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 잎사귀 노드의 최소 자료 수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_leaf, train_score, test_score, \"The minimum number of samples required to be at a leaf node\", \"min_samples_leaf\")\n",
    "    print(round(df_score_n, 4))\n",
    "    \n",
    "def model_final(algorithm, algorithm_name, feature_name, X_train, y_train, X_test, y_test, n_estimator, n_depth, n_split, n_leaf, selection):\n",
    "    # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "    if algorithm == DTC:\n",
    "        model = algorithm(random_state=1234, \n",
    "                          min_samples_leaf = n_leaf,\n",
    "                          min_samples_split = n_split, \n",
    "                          max_depth = n_depth)\n",
    "    else:\n",
    "        model = algorithm(random_state = 1234, \n",
    "                          n_estimators = n_estimator, \n",
    "                          min_samples_leaf = n_leaf,\n",
    "                          min_samples_split = n_split, \n",
    "                          max_depth = n_depth)\n",
    "    \n",
    "    if selection == 1 :\n",
    "        selector = RFECV(model, min_features_to_select=5, step=1, cv = 5)\n",
    "        selector.fit(X_train, y_train)\n",
    "        selected_columns = X.columns[selector.support_]\n",
    "\n",
    "        print(selected_columns)\n",
    "        train_acc = selector.score(X_train, y_train)\n",
    "        test_acc = selector.score(X_test, y_test)\n",
    "        y_pred = selector.predict(X_test)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, selector.predict_proba(X_test)[:,1])\n",
    "        print('AUC: {}'.format(roc_auc))\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\") # 정확도\n",
    "        print(f\"Precision: {precision_score(y_test, y_pred):.3f}\") # 정밀도\n",
    "        print(f\"Recall: {recall_score(y_test, y_pred):.3f}\") # 재현율\n",
    "        print(f\"F1-score: {f1_score(y_test, y_pred):.3f}\") # F1 스코어\n",
    "\n",
    "        # 혼동행렬 시각화\n",
    "#         plt.figure(figsize =(40, 40))\n",
    "#         plot_confusion_matrix(model, X_test, y_test,include_values = True,display_labels = ['non-negative', 'negative'],cmap = 'Pastel1') # 컬러맵\n",
    "#         plt.show()\n",
    "\n",
    "        # 변수 중요도 산출\n",
    "        dt_importance = pd.DataFrame()\n",
    "        dt_importance['Feature'] = feature_name # 설명변수 이름\n",
    "        dt_importance['Rank'] = selector.ranking_ # 설명변수 중요도 산출\n",
    "\n",
    "        # 변수 중요도 내림차순 정렬\n",
    "        dt_importance.sort_values(\"Rank\", ascending = False, inplace = True)\n",
    "        print(dt_importance.round(3))\n",
    "        # 변수 중요도 오름차순 정렬\n",
    "        dt_importance.sort_values(\"Rank\", ascending = True, inplace = True)\n",
    "        # 변수 중요도 시각화\n",
    "        coordinates = range(len(dt_importance)) # 설명변수 개수만큼 bar 시각화\n",
    "        plt.barh(y = coordinates, width = dt_importance[\"Rank\"])\n",
    "        plt.yticks(coordinates, dt_importance[\"Feature\"]) # y축 눈금별 설명변수 이름 기입\n",
    "        plt.xlabel(\"Feature Rank\") # x축 이름\n",
    "        plt.ylabel(\"Features\") # y축 이름\n",
    "    elif selection == 2:\n",
    "        mi_score = mutual_info_classif(X,y)\n",
    "        print(mi_score)\n",
    "        selector = SelectKBest(mutual_info_classif, k=7)\n",
    "        selector.fit(X_train, y_train)\n",
    "        X_train = selector.transform(X_train)\n",
    "        X_test = selector.transform(X_test)\n",
    "        filter = selector.get_support()\n",
    "        features = array(feature_name)\n",
    "        print(features[filter])\n",
    "        model.fit(X_train, y_train)\n",
    "        joblib.dump(model, '/Users/jun/Desktop/prof/Planned speech 2.0/gradient_KOR_model.pkl')\n",
    "        score=selector.scores_\n",
    "        \n",
    "        train_acc = model.score(X_train, y_train)\n",
    "        test_acc = model.score(X_test, y_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "        print('AUC: {}'.format(roc_auc))\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\") # 정확도\n",
    "        print(f\"Precision: {precision_score(y_test, y_pred):.3f}\") # 정밀도\n",
    "        print(f\"Recall: {recall_score(y_test, y_pred):.3f}\") # 재현율\n",
    "        print(f\"F1-score: {f1_score(y_test, y_pred):.3f}\") # F1 스코어\n",
    "\n",
    "        # 혼동행렬 시각화\n",
    "        plt.figure(figsize =(40, 40))\n",
    "        plot_confusion_matrix(model, X_test, y_test,include_values = True,display_labels = ['non-negative', 'negative'],cmap = 'Pastel1') # 컬러맵\n",
    "        plt.show()\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "        # 최종 모델의 성능 평가\n",
    "        train_acc = model.score(X_train, y_train)\n",
    "        test_acc = model.score(X_test, y_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "        print('AUC: {}'.format(roc_auc))\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\") # 정확도\n",
    "        print(f\"Precision: {precision_score(y_test, y_pred):.3f}\") # 정밀도\n",
    "        print(f\"Recall: {recall_score(y_test, y_pred):.3f}\") # 재현율\n",
    "        print(f\"F1-score: {f1_score(y_test, y_pred):.3f}\") # F1 스코어\n",
    "\n",
    "        # 혼동행렬 시각화\n",
    "        plt.figure(figsize =(40, 40))\n",
    "        plot_confusion_matrix(model, X_test, y_test,include_values = True,display_labels = ['non-negative', 'negative'],cmap = 'Pastel1') # 컬러맵\n",
    "        plt.show()\n",
    "\n",
    "        # 변수 중요도 산출\n",
    "        dt_importance = pd.DataFrame()\n",
    "        dt_importance['Feature'] = feature_name # 설명변수 이름\n",
    "        dt_importance['Importance'] = model.feature_importances_ # 설명변수 중요도 산출\n",
    "\n",
    "        # 변수 중요도 내림차순 정렬\n",
    "        dt_importance.sort_values(\"Importance\", ascending = False, inplace = True)\n",
    "        print(dt_importance.round(3))\n",
    "        # 변수 중요도 오름차순 정렬\n",
    "        dt_importance.sort_values(\"Importance\", ascending = True, inplace = True)\n",
    "        # 변수 중요도 시각화\n",
    "        coordinates = range(len(dt_importance)) # 설명변수 개수만큼 bar 시각화\n",
    "        plt.barh(y = coordinates, width = dt_importance[\"Importance\"])\n",
    "        plt.yticks(coordinates, dt_importance[\"Feature\"]) # y축 눈금별 설명변수 이름 기입\n",
    "        plt.xlabel(\"Feature Importance\") # x축 이름\n",
    "        plt.ylabel(\"Features\") # y축 이름\n",
    "        \n",
    "    \n",
    "\n",
    "algorithm = GBC\n",
    "algorithm_name = 'gbc'\n",
    "train_acc_before, test_acc_before = modeling_uncustomized(algorithm, \n",
    "                                                          X_train,\n",
    "                                                          y_train,\n",
    "                                                          X_test,\n",
    "                                                          y_test)\n",
    "\n",
    "n_estimator = 135\n",
    "n_depth = 12\n",
    "n_split = 26\n",
    "n_leaf = 22\n",
    "\n",
    "model_final(algorithm, algorithm_name, feature_name,\n",
    "            X_train, y_train, X_test, y_test,\n",
    "            n_estimator, n_depth, n_split, n_leaf,selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b7f0148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4460\n",
      "1    4460\n",
      "Name: sentiment, dtype: int64\n",
      "학습 데이터셋 정확도: 0.871\n",
      "테스트 데이터셋 정확도: 0.801\n",
      "[0.03633934 0.00010921 0.01844757 0.0199874  0.04749473 0.06361859\n",
      " 0.06526177 0.00276064 0.00222304 0.         0.00120885 0.\n",
      " 0.00207609 0.00367718 0.00111057 0.00208687 0.02123934 0.00392515\n",
      " 0.00463629 0.00797484 0.00576925 0.00791244]\n",
      "['Game_Runtime' 'Hunger_PLAYER' 'Health_PLAYER' 'Sanity_PLAYER'\n",
      " 'Player_Xloc' 'Player_Zloc' 'Curr_Inv_Cnt_PLAYER']\n",
      "AUC: 0.971608298927134\n",
      "Accuracy: 0.958\n",
      "Precision: 0.569\n",
      "Recall: 0.884\n",
      "F1-score: 0.693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x2880 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ENG 5sec - feature selection(2) - under sampling(1/3) + SMOTE\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from numpy import array \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "import warnings; warnings.filterwarnings(action='ignore') # 경고 메시지 무시\n",
    "import matplotlib.pyplot as plt # 데이터 시각화 라이브러리\n",
    "import pickle # 객체 입출력을 위한 라이브러리\n",
    "from sklearn.model_selection import train_test_split # 훈련 데이터, 테스트 데이터 분리\n",
    "from sklearn.preprocessing import StandardScaler # 정규화\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC # 랜덤포레스트 분류 알고리즘\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC # 의사결정나무 분류 알고리즘\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC # 그래디언트 부스팅 분류 알고리즘\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, plot_confusion_matrix\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "import joblib\n",
    "########################\n",
    "\n",
    "UnderSampling = 1       # 1 : undersampling(size->1/3), 2 : undersampling(size->minority),   0 : not undersampling    \n",
    "OverSampling = 1        # 1 : oversampling(SMOTE),                                           0 : not oversampling\n",
    "selection = 2           # 1 : feature selection - RFEVC, 2 : feature selection - mutual information, 0 : not feature selection\n",
    "feat_start=1\n",
    "########################\n",
    "data = pd.read_csv('/Users/jun/Data/sentiment analysis - ENG/5초전/사용할 파일/sentiment+gamedata/ENG-5sec(fin).csv')\n",
    "scaler = StandardScaler()\n",
    "y = data['sentiment']\n",
    "X = data.drop(labels=['sentiment','file','time'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,random_state=7)\n",
    "# 설명변수 데이터 스케일링\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "feature_name = X.columns\n",
    "if UnderSampling == 1:\n",
    "    undersample = RandomUnderSampler(sampling_strategy=0.1686) \n",
    "    X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "elif UnderSampling == 2:\n",
    "    undersample = RandomUnderSampler(sampling_strategy='majority') \n",
    "    X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "    \n",
    "if OverSampling == 1:\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    \n",
    "print(y_train.value_counts())\n",
    "\n",
    "def modeling_uncustomized (algorithm, X_train, y_train, X_test, y_test):\n",
    "    # 하이퍼파라미터 조정 없이 모델 학습\n",
    "    uncustomized = algorithm(random_state=1234)\n",
    "    uncustomized.fit(X_train, y_train)\n",
    "    # Train Data 설명력\n",
    "    train_score_before = uncustomized.score(X_train, y_train).round(3)\n",
    "    print(f\"학습 데이터셋 정확도: {train_score_before}\")\n",
    "    # Test Data 설명력\n",
    "    test_score_before = uncustomized.score(X_test, y_test).round(3)\n",
    "    print(f\"테스트 데이터셋 정확도: {test_score_before}\")\n",
    "    return train_score_before, test_score_before\n",
    "\n",
    "\n",
    "def optimi_visualization(algorithm_name, X_values, train_score, test_score, xlabel, filename):\n",
    "    # 하이퍼파라미터 조정에 따른 학습 데이터셋 기반 모델 성능 추이 시각화\n",
    "    plt.plot(X_values, train_score, linestyle = '-', label = 'train score')\n",
    "    # 하이퍼파라미터 조정에 따른 테스트 데이터셋 기반 모델 성능 추이 시각화\n",
    "    plt.plot(X_values, test_score, linestyle = '--', label = 'test score')\n",
    "    plt.ylabel('Accuracy(%)') # y축 라벨\n",
    "    plt.xlabel(xlabel) # x축 라벨\n",
    "    plt.legend() # 범례표시\n",
    "    \n",
    "def optimi_estimator(algorithm, algorithm_name, X_train, y_train, X_test, y_test, n_estimator_min, n_estimator_max):\n",
    "    train_score = []; test_score =[]\n",
    "    para_n_tree = [n_tree*5 for n_tree in range(n_estimator_min, n_estimator_max)]\n",
    "\n",
    "    for v_n_estimators in para_n_tree:\n",
    "        model = algorithm(n_estimators = v_n_estimators, random_state=1234)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 트리 개수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'n_estimators': para_n_tree, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 트리 개수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_n_tree, train_score, test_score, \"The number of estimator\", \"n_estimator\")\n",
    "    print(round(df_score_n, 4))\n",
    "\n",
    "\n",
    "def optimi_maxdepth (algorithm, algorithm_name, X_train, y_train, X_test, y_test, depth_min, depth_max, n_estimator):\n",
    "    train_score = []; test_score = []\n",
    "    para_depth = [depth for depth in range(depth_min, depth_max)]\n",
    "\n",
    "    for v_max_depth in para_depth:\n",
    "        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "        if algorithm == DTC:\n",
    "            model = algorithm(max_depth = v_max_depth,\n",
    "                              random_state=1234)\n",
    "        else:\n",
    "            model = algorithm(max_depth = v_max_depth,\n",
    "                              n_estimators = n_estimator,\n",
    "                              random_state=1234)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 최대 깊이에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'depth': para_depth, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 최대 깊이에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_depth, train_score, test_score, \"The number of depth\", \"n_depth\")\n",
    "    print(round(df_score_n, 4))\n",
    "    \n",
    "def optimi_minsplit (algorithm, algorithm_name, X_train, y_train, X_test, y_test, n_split_min, n_split_max, n_estimator, n_depth):\n",
    "    train_score = []; test_score = []\n",
    "    para_split = [n_split*2 for n_split in range(n_split_min, n_split_max)]\n",
    "    for v_min_samples_split in para_split:\n",
    "        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "        if algorithm == DTC:\n",
    "            model = algorithm(min_samples_split = v_min_samples_split,\n",
    "                              max_depth = n_depth,\n",
    "                              random_state = 1234)\n",
    "        else:\n",
    "            model = algorithm(min_samples_split = v_min_samples_split,\n",
    "                              n_estimators = n_estimator,\n",
    "                              max_depth = n_depth,\n",
    "                              random_state = 1234)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 분리 노드의 최소 자료 수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'min_samples_split': para_split, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 분리 노드의 최소 자료 수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_split, train_score, test_score, \"The minimum number of samples required to split an internal node\", \"min_samples_split\")\n",
    "    print(round(df_score_n, 4))\n",
    "    \n",
    "def optimi_minleaf(algorithm, algorithm_name, X_train, y_train, X_test, y_test, n_leaf_min, n_leaf_max, n_estimator, n_depth, n_split):\n",
    "    train_score = []; test_score = []\n",
    "    para_leaf = [n_leaf*2 for n_leaf in range(n_leaf_min, n_leaf_max)]\n",
    "\n",
    "    for v_min_samples_leaf in para_leaf:\n",
    "        # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "        if algorithm == DTC:\n",
    "            model = algorithm(min_samples_leaf = v_min_samples_leaf,\n",
    "                                        max_depth = n_depth,\n",
    "                                        min_samples_split = n_split,\n",
    "                                        random_state=1234)\n",
    "        else:\n",
    "            model = algorithm(min_samples_leaf = v_min_samples_leaf,\n",
    "                                n_estimators = n_estimator,\n",
    "                                max_depth = n_depth,\n",
    "                                min_samples_split = n_split,\n",
    "                                random_state=1234)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "\n",
    "    # 잎사귀 노드의 최소 자료 수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'min_samples_leaf': para_leaf, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 잎사귀 노드의 최소 자료 수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_leaf, train_score, test_score, \"The minimum number of samples required to be at a leaf node\", \"min_samples_leaf\")\n",
    "    print(round(df_score_n, 4))\n",
    "    \n",
    "def model_final(algorithm, algorithm_name, feature_name, X_train, y_train, X_test, y_test, n_estimator, n_depth, n_split, n_leaf, selection):\n",
    "    # 의사결정나무 모델의 경우 트리 개수를 따로 설정하지 않기 때문에 RFC, GBC와 분리하여 모델링\n",
    "    if algorithm == DTC:\n",
    "        model = algorithm(random_state=1234, \n",
    "                          min_samples_leaf = n_leaf,\n",
    "                          min_samples_split = n_split, \n",
    "                          max_depth = n_depth)\n",
    "    else:\n",
    "        model = algorithm(random_state = 1234, \n",
    "                          n_estimators = n_estimator, \n",
    "                          min_samples_leaf = n_leaf,\n",
    "                          min_samples_split = n_split, \n",
    "                          max_depth = n_depth)\n",
    "    \n",
    "    if selection == 1 :\n",
    "        selector = RFECV(model, min_features_to_select=5, step=1, cv = 5)\n",
    "        selector.fit(X_train, y_train)\n",
    "        selected_columns = X.columns[selector.support_]\n",
    "\n",
    "        print(selected_columns)\n",
    "        train_acc = selector.score(X_train, y_train)\n",
    "        test_acc = selector.score(X_test, y_test)\n",
    "        y_pred = selector.predict(X_test)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, selector.predict_proba(X_test)[:,1])\n",
    "        print('AUC: {}'.format(roc_auc))\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\") # 정확도\n",
    "        print(f\"Precision: {precision_score(y_test, y_pred):.3f}\") # 정밀도\n",
    "        print(f\"Recall: {recall_score(y_test, y_pred):.3f}\") # 재현율\n",
    "        print(f\"F1-score: {f1_score(y_test, y_pred):.3f}\") # F1 스코어\n",
    "\n",
    "        # 혼동행렬 시각화\n",
    "#         plt.figure(figsize =(40, 40))\n",
    "#         plot_confusion_matrix(model, X_test, y_test,include_values = True,display_labels = ['non-negative', 'negative'],cmap = 'Pastel1') # 컬러맵\n",
    "#         plt.show()\n",
    "\n",
    "        # 변수 중요도 산출\n",
    "        dt_importance = pd.DataFrame()\n",
    "        dt_importance['Feature'] = feature_name # 설명변수 이름\n",
    "        dt_importance['Rank'] = selector.ranking_ # 설명변수 중요도 산출\n",
    "\n",
    "        # 변수 중요도 내림차순 정렬\n",
    "        dt_importance.sort_values(\"Rank\", ascending = False, inplace = True)\n",
    "        print(dt_importance.round(3))\n",
    "        # 변수 중요도 오름차순 정렬\n",
    "        dt_importance.sort_values(\"Rank\", ascending = True, inplace = True)\n",
    "        # 변수 중요도 시각화\n",
    "        coordinates = range(len(dt_importance)) # 설명변수 개수만큼 bar 시각화\n",
    "        plt.barh(y = coordinates, width = dt_importance[\"Rank\"])\n",
    "        plt.yticks(coordinates, dt_importance[\"Feature\"]) # y축 눈금별 설명변수 이름 기입\n",
    "        plt.xlabel(\"Feature Rank\") # x축 이름\n",
    "        plt.ylabel(\"Features\") # y축 이름\n",
    "    elif selection == 2:\n",
    "        mi_score = mutual_info_classif(X,y)\n",
    "        print(mi_score)\n",
    "        selector = SelectKBest(mutual_info_classif, k=7)\n",
    "        selector.fit(X_train, y_train)\n",
    "        X_train = selector.transform(X_train)\n",
    "        X_test = selector.transform(X_test)\n",
    "        filter = selector.get_support()\n",
    "        features = array(feature_name)\n",
    "        print(features[filter])\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "        joblib.dump(model, '/Users/jun/Desktop/prof/Planned speech 2.0/gradient_ENG_model.pkl') \n",
    "        score=selector.scores_\n",
    "        \n",
    "        train_acc = model.score(X_train, y_train)\n",
    "        test_acc = model.score(X_test, y_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "        print('AUC: {}'.format(roc_auc))\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\") # 정확도\n",
    "        print(f\"Precision: {precision_score(y_test, y_pred):.3f}\") # 정밀도\n",
    "        print(f\"Recall: {recall_score(y_test, y_pred):.3f}\") # 재현율\n",
    "        print(f\"F1-score: {f1_score(y_test, y_pred):.3f}\") # F1 스코어\n",
    "\n",
    "        # 혼동행렬 시각화\n",
    "        plt.figure(figsize =(40, 40))\n",
    "        plot_confusion_matrix(model, X_test, y_test,include_values = True,display_labels = ['non-negative', 'negative'],cmap = 'Pastel1') # 컬러맵\n",
    "        plt.show()\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "        # 최종 모델의 성능 평가\n",
    "        train_acc = model.score(X_train, y_train)\n",
    "        test_acc = model.score(X_test, y_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        roc_auc = metrics.roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "        print('AUC: {}'.format(roc_auc))\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\") # 정확도\n",
    "        print(f\"Precision: {precision_score(y_test, y_pred):.3f}\") # 정밀도\n",
    "        print(f\"Recall: {recall_score(y_test, y_pred):.3f}\") # 재현율\n",
    "        print(f\"F1-score: {f1_score(y_test, y_pred):.3f}\") # F1 스코어\n",
    "\n",
    "        # 혼동행렬 시각화\n",
    "        plt.figure(figsize =(40, 40))\n",
    "        plot_confusion_matrix(model, X_test, y_test,include_values = True,display_labels = ['non-negative', 'negative'],cmap = 'Pastel1') # 컬러맵\n",
    "        plt.show()\n",
    "\n",
    "        # 변수 중요도 산출\n",
    "        dt_importance = pd.DataFrame()\n",
    "        dt_importance['Feature'] = feature_name # 설명변수 이름\n",
    "        dt_importance['Importance'] = model.feature_importances_ # 설명변수 중요도 산출\n",
    "\n",
    "        # 변수 중요도 내림차순 정렬\n",
    "        dt_importance.sort_values(\"Importance\", ascending = False, inplace = True)\n",
    "        print(dt_importance.round(3))\n",
    "        # 변수 중요도 오름차순 정렬\n",
    "        dt_importance.sort_values(\"Importance\", ascending = True, inplace = True)\n",
    "        # 변수 중요도 시각화\n",
    "        coordinates = range(len(dt_importance)) # 설명변수 개수만큼 bar 시각화\n",
    "        plt.barh(y = coordinates, width = dt_importance[\"Importance\"])\n",
    "        plt.yticks(coordinates, dt_importance[\"Feature\"]) # y축 눈금별 설명변수 이름 기입\n",
    "        plt.xlabel(\"Feature Importance\") # x축 이름\n",
    "        plt.ylabel(\"Features\") # y축 이름\n",
    "        \n",
    "    \n",
    "\n",
    "algorithm = GBC\n",
    "algorithm_name = 'gbc'\n",
    "train_acc_before, test_acc_before = modeling_uncustomized(algorithm, \n",
    "                                                          X_train,\n",
    "                                                          y_train,\n",
    "                                                          X_test,\n",
    "                                                          y_test)\n",
    "\n",
    "n_estimator = 150\n",
    "n_depth = 11\n",
    "n_split = 112\n",
    "n_leaf = 12\n",
    "\n",
    "model_final(algorithm, algorithm_name, feature_name,\n",
    "            X_train, y_train, X_test, y_test,\n",
    "            n_estimator, n_depth, n_split, n_leaf,selection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
